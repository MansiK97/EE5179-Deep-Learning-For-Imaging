{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PA1_EE21S063_DL_PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ya7_9_fxV_TY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision.datasets as data\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WVXiEQ3WJGp",
        "outputId": "94959160-0bc8-4484-b8bf-8316e9afd178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = data.MNIST(root = 'MNIST/raw/train-images-idx3-ubyte', train = True, transform= ToTensor(), download = True)\n",
        "test_set = data.MNIST(root= 'MNIST/raw/train-images-idx3-ubyte', train= False, transform= ToTensor())\n",
        "\n",
        "train_features = train_set.data\n",
        "train_labels = train_set.targets"
      ],
      "metadata": {
        "id": "NlILoAvqWKLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display image and label.\n",
        "\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[10].squeeze()\n",
        "label = train_labels[10]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "0h0tWRthbqQC",
        "outputId": "6aafd04e-f6d2-45a5-8b1f-d393f7f1d0e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([60000, 28, 28])\n",
            "Labels batch shape: torch.Size([60000])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "learning_rate = 0.01\n",
        "input_size = (train_features.reshape(train_features.shape[0],-1)).shape[1]\n",
        "hidden_layer_1 = 500\n",
        "hidden_layer_2 = 250\n",
        "hidden_layer_3 = 100\n",
        "output_layer = 10\n",
        "momentum = 0.5\n",
        "log_interval = 10\n",
        "\n",
        "random_seed = 1\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kB4ZtA96cFyO",
        "outputId": "ab2b981c-b625-489a-b9f5-7db49f4d840c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ff6e8d6d510>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(data.MNIST('/files/', train=True, download=True, transform = ToTensor()),batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(data.MNIST('/files/', train=False, download=True,transform=ToTensor()),batch_size=batch_size_test, shuffle=True)"
      ],
      "metadata": {
        "id": "UUuHYUkQcn4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class classificationmodel_sigmoid(nn.Module):\n",
        "  def __init__(self, input_size, hidden_layer_1, hidden_layer_2, hidden_layer_3, output_layer):\n",
        "    super(classificationmodel_sigmoid,self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_layer_1)\n",
        "    self.linear2 = nn.Linear(hidden_layer_1, hidden_layer_2)\n",
        "    self.linear3 = nn.Linear(hidden_layer_2, hidden_layer_3)\n",
        "    self.linear4 = nn.Linear(hidden_layer_3, output_layer)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "  def forward(self, image):\n",
        "    a = image.view(-1, input_size)\n",
        "    a = self.linear1(a)\n",
        "    a = self.sigmoid(a)\n",
        "    a = self.linear2(a)\n",
        "    a = self.sigmoid(a)\n",
        "    a = self.linear3(a)\n",
        "    a = self.sigmoid(a)\n",
        "    a = self.linear4(a)\n",
        "    a = self.softmax(a)\n",
        "    return a"
      ],
      "metadata": {
        "id": "KKGZoA8y8ACD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_sigmoid = classificationmodel_sigmoid(input_size, hidden_layer_1, hidden_layer_2, hidden_layer_3, output_layer)"
      ],
      "metadata": {
        "id": "g7XDO3Bo8rve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class classificationmodel_relu(nn.Module):\n",
        "  def __init__(self, input_size, hidden_layer_1, hidden_layer_2, hidden_layer_3, output_layer):\n",
        "    super(classificationmodel_relu,self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_layer_1)\n",
        "    self.linear2 = nn.Linear(hidden_layer_1, hidden_layer_2)\n",
        "    self.linear3 = nn.Linear(hidden_layer_2, hidden_layer_3)\n",
        "    self.linear4 = nn.Linear(hidden_layer_3, output_layer)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "  def forward(self, image):\n",
        "    a = image.view(-1, input_size)\n",
        "    a = self.linear1(a)\n",
        "    a = self.relu(a)\n",
        "    a = self.linear2(a)\n",
        "    a = self.relu(a)\n",
        "    a = self.linear3(a)\n",
        "    a = self.relu(a)\n",
        "    a = self.linear4(a)\n",
        "    a = self.softmax(a)\n",
        "    return a"
      ],
      "metadata": {
        "id": "wXGmMidmCbhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_relu = classificationmodel_relu(input_size, hidden_layer_1, hidden_layer_2, hidden_layer_3, output_layer)"
      ],
      "metadata": {
        "id": "6ex4YuqDG3d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class classificationmodel_tanh(nn.Module):\n",
        "  def __init__(self, input_size, hidden_layer_1, hidden_layer_2, hidden_layer_3, output_layer):\n",
        "    super(classificationmodel_tanh,self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_layer_1)\n",
        "    self.linear2 = nn.Linear(hidden_layer_1, hidden_layer_2)\n",
        "    self.linear3 = nn.Linear(hidden_layer_2, hidden_layer_3)\n",
        "    self.linear4 = nn.Linear(hidden_layer_3, output_layer)\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "  def forward(self, image):\n",
        "    a = image.view(-1, input_size)\n",
        "    a = self.linear1(a)\n",
        "    a = self.tanh(a)\n",
        "    a = self.linear2(a)\n",
        "    a = self.tanh(a)\n",
        "    a = self.linear3(a)\n",
        "    a = self.tanh(a)\n",
        "    a = self.linear4(a)\n",
        "    a = self.softmax(a)\n",
        "    return a"
      ],
      "metadata": {
        "id": "x0FG-XYI9HE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_tanh = classificationmodel_tanh(input_size, hidden_layer_1, hidden_layer_2, hidden_layer_3, output_layer)"
      ],
      "metadata": {
        "id": "tDbH3Mn79Yso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "def train(model, optimizer):\n",
        "  n_steps = len(train_loader)\n",
        "  for e in range(n_epochs):\n",
        "      running_loss = 0\n",
        "      iter = 0\n",
        "      print(f'epoch = {e}')\n",
        "      for x, (images, labels) in enumerate(train_loader):\n",
        "        # Flatten the Image from 28*28 to 784 column vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "        \n",
        "        # setting gradient to zeros   \n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        optimizer.zero_grad()    \n",
        "        # backward propagation\n",
        "        loss.backward()\n",
        "        # update the gradient to new gradients\n",
        "        optimizer.step()\n",
        "        if (x+1)%100 == 0:\n",
        "          running_loss += loss.item()\n",
        "        iter +=1\n",
        "        if iter % 500 == 0:\n",
        "          # Calculate Accuracy         \n",
        "          correct = 0\n",
        "          total = 0\n",
        "          # Iterate through test dataset\n",
        "          for images, labels in test_loader:\n",
        "            # Load images to a Torch Variable\n",
        "            images = images.view(images.shape[0], -1)\n",
        "            \n",
        "            # Forward pass only to get logits/output\n",
        "            outputs = model(images)\n",
        "            \n",
        "            # Get predictions from the maximum value\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            \n",
        "            # Total number of labels\n",
        "            total += labels.size(0)\n",
        "            \n",
        "            # Total correct predictions\n",
        "            correct += (predicted == labels).sum()\n",
        "        \n",
        "          accuracy = 100 * correct / total\n",
        "          \n",
        "          # Print Loss\n",
        "          print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n",
        "  print(f'epochs [{e+1}/{n_epochs}],Step[{x+1}/{n_steps}],Losses:  {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "i_2gJBtNuj1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model, data_loader):\n",
        "  model.eval()\n",
        "  loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for image, label in data_loader:\n",
        "      output = model(image)\n",
        "      loss  += criterion(output, label).item()\n",
        "      pred = output.argmax(dim = 1, keepdim = True)\n",
        "      correct += pred.eq(label.view_as(pred)).sum().item()\n",
        "  \n",
        "  loss /=len(data_loader.dataset)\n",
        "\n",
        "  print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        loss, correct, len(data_loader.dataset),\n",
        "        100. * correct / len(data_loader.dataset)))\n"
      ],
      "metadata": {
        "id": "iEgYgYwTlsPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_sigmoid = torch.optim.Adam(model_sigmoid.parameters(), lr = learning_rate)\n",
        "optimizer_relu = torch.optim.Adam(model_relu.parameters(), lr = learning_rate)\n",
        "optimizer_tanh = torch.optim.Adam(model_tanh.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "f1egNp0guUfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training for Sigmoid Activation**"
      ],
      "metadata": {
        "id": "WSOPvHAF-qsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(model_sigmoid, optimizer_sigmoid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWaKtXR79tJd",
        "outputId": "22a5220a-4292-4958-c6bb-d32c819bf6a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0\n",
            "Iteration: 500. Loss: 0.02223104238510132. Accuracy: 96.38999938964844\n",
            "epoch = 1\n",
            "Iteration: 500. Loss: 0.07424124330282211. Accuracy: 96.88999938964844\n",
            "epoch = 2\n",
            "Iteration: 500. Loss: 0.13215449452400208. Accuracy: 96.62000274658203\n",
            "epoch = 3\n",
            "Iteration: 500. Loss: 0.020750051364302635. Accuracy: 96.68000030517578\n",
            "epoch = 4\n",
            "Iteration: 500. Loss: 0.009185138158500195. Accuracy: 96.94000244140625\n",
            "epochs [5/5],Step[938/938],Losses:  0.1411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('On the Train Set: ')\n",
        "accuracy(model_sigmoid, train_loader)\n",
        "print('On the Test Set: ')\n",
        "accuracy(model_sigmoid, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4KXOWeQ7srm",
        "outputId": "5980539a-237b-49d6-8031-297c807cd37c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On the Train Set: \n",
            "\n",
            "Average loss: 0.0010, Accuracy: 58813/60000 (98%)\n",
            "\n",
            "On the Test Set: \n",
            "\n",
            "Average loss: 0.0001, Accuracy: 9679/10000 (97%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training for ReLU activation**"
      ],
      "metadata": {
        "id": "qy74nYpK-zLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(model_relu, optimizer_relu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emkoEtJ6-m7a",
        "outputId": "0ea117f1-8d58-4238-9a42-fe6daf571824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0\n",
            "Iteration: 500. Loss: 0.16824673116207123. Accuracy: 93.94000244140625\n",
            "epoch = 1\n",
            "Iteration: 500. Loss: 0.08231014013290405. Accuracy: 96.4000015258789\n",
            "epoch = 2\n",
            "Iteration: 500. Loss: 0.2521880269050598. Accuracy: 96.16999816894531\n",
            "epoch = 3\n",
            "Iteration: 500. Loss: 0.20854493975639343. Accuracy: 96.41000366210938\n",
            "epoch = 4\n",
            "Iteration: 500. Loss: 0.04136047512292862. Accuracy: 96.1500015258789\n",
            "epochs [5/5],Step[938/938],Losses:  0.1098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('On the Train Set: ')\n",
        "accuracy(model_relu, train_loader)\n",
        "print('On the Test Set: ')\n",
        "accuracy(model_relu, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTzvkGyf_Ze0",
        "outputId": "2fa375f1-4833-4080-dd7c-f0fe707b8015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On the Train Set: \n",
            "\n",
            "Average loss: 0.0016, Accuracy: 58498/60000 (97%)\n",
            "\n",
            "On the Test Set: \n",
            "\n",
            "Average loss: 0.0002, Accuracy: 9620/10000 (96%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training for TanH Activation**"
      ],
      "metadata": {
        "id": "TMHFczOB_af4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(model_tanh, optimizer_tanh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8t96gU7_hGu",
        "outputId": "620f18d0-1203-4bee-f128-4d733a846a40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0\n",
            "Iteration: 500. Loss: 0.41016891598701477. Accuracy: 90.2300033569336\n",
            "epoch = 1\n",
            "Iteration: 500. Loss: 0.46348047256469727. Accuracy: 85.3499984741211\n",
            "epoch = 2\n",
            "Iteration: 500. Loss: 0.2446739375591278. Accuracy: 85.9800033569336\n",
            "epoch = 3\n",
            "Iteration: 500. Loss: 0.48340320587158203. Accuracy: 87.58999633789062\n",
            "epoch = 4\n",
            "Iteration: 500. Loss: 0.9405316114425659. Accuracy: 82.93000030517578\n",
            "epochs [5/5],Step[938/938],Losses:  0.2936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('On the Train Set: ')\n",
        "accuracy(model_tanh, train_loader)\n",
        "print('On the Test Set: ')\n",
        "accuracy(model_tanh, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dki6Zhbl_len",
        "outputId": "2175c59c-706d-4911-9eba-c4ef052ddef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On the Train Set: \n",
            "\n",
            "Average loss: 0.0069, Accuracy: 52729/60000 (88%)\n",
            "\n",
            "On the Test Set: \n",
            "\n",
            "Average loss: 0.0004, Accuracy: 8785/10000 (88%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def view_classify(img, ps):\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    ax2.set_yticklabels(np.arange(10))\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "id": "gJGvE2X1vIRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the image to test\n",
        "images, labels = next(iter(train_loader))\n",
        "# Flatten the image to pass in the model\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "view_classify(img, ps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "pKDFA5dOvCer",
        "outputId": "f4ab2013-f25b-4002-fc50-9532b72c32d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations:\n",
        "\n",
        "## Sigmoid gives accuracy as:\n",
        "  * **Training: 98%**\n",
        "  * **Testing: 97%**\n",
        "\n",
        "## ReLU gives accuracy as:\n",
        "  * **Training: 97%**\n",
        "  * **Testing: 96%**\n",
        "\n",
        "## TanH gives accuracy as:\n",
        "  * **Training: 88%**\n",
        "  * **Testing: 88%**\n",
        "\n"
      ],
      "metadata": {
        "id": "s06z9XkFTDh_"
      }
    }
  ]
}